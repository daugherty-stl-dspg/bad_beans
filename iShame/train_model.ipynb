{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Dense, Activation, MaxPooling2D, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.metrics import MeanSquaredError, CategoricalAccuracy\n",
    "\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filepath):\n",
    "    data_file = h5py.File(filepath,'r')\n",
    "\n",
    "    train_data = data_file['train_data'][:]\n",
    "    train_labels = data_file['train_labels'][:]\n",
    "\n",
    "    test_data = data_file['test_data'][:]\n",
    "    test_labels = data_file['test_labels'][:]\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iShameModel(input_shape, conv_layers, conn_layers, output_classes=None):\n",
    "\n",
    "    # input layer\n",
    "    X_input = Input(input_shape)\n",
    "    X = X_input\n",
    "\n",
    "    # convlutional layers\n",
    "    # CONV2D -> RELU -> MAXPOOL\n",
    "    # number of filters, filter_size, and strides retrieved from input conv array\n",
    "\n",
    "    for idx, layer in enumerate(conv_layers):        \n",
    "        X = Conv2D(layer[\"num_filters\"], layer[\"filter_size\"], strides = layer[\"filter_size\"], \\\n",
    "                    name = 'conv_'+str(idx), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "        #X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "        X = Activation(layer[\"activation\"])(X)\n",
    "        X = MaxPooling2D(layer[\"filter_size\"], strides=layer[\"stride_size\"], name=\"max_pool_\"+str(idx))(X)\n",
    "\n",
    "    # add fully connected layers\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    for idx, layer in enumerate(conn_layers):\n",
    "        X = Dense(layer[\"hidden_units\"], activation=layer[\"activation\"], name=\"fully_connected_\"+str(idx))(X)\n",
    "\n",
    "    # if classification, add softmax output layer\n",
    "    # otherwise, add singular output layer with one unit with NO activation\n",
    "    if output_classes is not None:\n",
    "        X = Dense(output_classes, activation='softmax', name='class_output_'+str(output_classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    else:\n",
    "        X = Dense(1, name = 'regression_output')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='iShame')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training, test data\n",
    "\n",
    "data_save_path = '../img/label_data'\n",
    "data_set_name='coffee_label_data.h5'\n",
    "filepath=os.path.join(data_save_path,data_set_name)\n",
    "train_data, train_labels, test_data, test_labels  = get_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(97, 540, 960, 3)\n"
    }
   ],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [{\"num_filters\": 16,\n",
    "                \"filter_size\": (3,3),\n",
    "                \"stride_size\": (1,1),\n",
    "                \"activation\": \"relu\",\n",
    "                \"pool_size\": (2,2)\n",
    "                },\n",
    "                {\"num_filters\": 32,\n",
    "                \"filter_size\": (3,3),\n",
    "                \"stride_size\": (1,1),\n",
    "                \"activation\": \"relu\",\n",
    "                \"pool_size\": (2,2)\n",
    "                },\n",
    "                {\"num_filters\": 64,\n",
    "                \"filter_size\": (3,3),\n",
    "                \"stride_size\": (1,1),\n",
    "                \"activation\": \"relu\",\n",
    "                \"pool_size\": (2,2)\n",
    "                }]\n",
    "conn_layers = [{\"hidden_units\": 500,\n",
    "                    \"activation\": \"relu\"},\n",
    "                {\"hidden_units\": 100,\n",
    "                    \"activation\": \"relu\"},\n",
    "                {\"hidden_units\": 20,\n",
    "                    \"activation\": \"relu\"}\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_output = False\n",
    "if(regression_output):\n",
    "    num_classes=None\n",
    "    loss=\"mean_squared_error\"\n",
    "    metrics=[MeanSquaredError()]\n",
    "else:\n",
    "    num_classes=train_labels.shape[-1]\n",
    "    loss=\"categorical_crossentropy\"\n",
    "    metrics=[CategoricalAccuracy()]\n",
    "batch_size=32\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = iShameModel(input_shape=train_data.shape[1:],conv_layers=conv_layers,conn_layers=conn_layers,output_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n387/387 [==============================] - 80s 206ms/step - loss: 0.1018 - categorical_accuracy: 0.9173\nEpoch 2/10\n387/387 [==============================] - 61s 157ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\nEpoch 3/10\n387/387 [==============================] - 61s 158ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\nEpoch 4/10\n387/387 [==============================] - 62s 160ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\nEpoch 5/10\n387/387 [==============================] - 63s 162ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\nEpoch 6/10\n387/387 [==============================] - 61s 159ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\nEpoch 7/10\n387/387 [==============================] - 61s 158ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\nEpoch 8/10\n387/387 [==============================] - 62s 160ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\nEpoch 9/10\n387/387 [==============================] - 61s 157ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\nEpoch 10/10\n387/387 [==============================] - 61s 159ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x7f96441844e0>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "97/97 [==============================] - 10s 101ms/step\nLoss: 0.0\nResult: 1.0\n"
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(\"Loss:\",results[0])\n",
    "print(\"Result:\",results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"iShame\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         (None, 540, 960, 3)       0         \n_________________________________________________________________\nconv_0 (Conv2D)              (None, 180, 320, 16)      448       \n_________________________________________________________________\nactivation_7 (Activation)    (None, 180, 320, 16)      0         \n_________________________________________________________________\nmax_pool_0 (MaxPooling2D)    (None, 178, 318, 16)      0         \n_________________________________________________________________\nconv_1 (Conv2D)              (None, 59, 106, 32)       4640      \n_________________________________________________________________\nactivation_8 (Activation)    (None, 59, 106, 32)       0         \n_________________________________________________________________\nmax_pool_1 (MaxPooling2D)    (None, 57, 104, 32)       0         \n_________________________________________________________________\nconv_2 (Conv2D)              (None, 19, 34, 64)        18496     \n_________________________________________________________________\nactivation_9 (Activation)    (None, 19, 34, 64)        0         \n_________________________________________________________________\nmax_pool_2 (MaxPooling2D)    (None, 17, 32, 64)        0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 34816)             0         \n_________________________________________________________________\nfully_connected_0 (Dense)    (None, 500)               17408500  \n_________________________________________________________________\nfully_connected_1 (Dense)    (None, 100)               50100     \n_________________________________________________________________\nfully_connected_2 (Dense)    (None, 20)                2020      \n_________________________________________________________________\nclass_output_3 (Dense)       (None, 3)                 63        \n=================================================================\nTotal params: 17,484,267\nTrainable params: 17,484,267\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-52d09bb01d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ImportError(\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "opencv",
   "display_name": "opencv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}